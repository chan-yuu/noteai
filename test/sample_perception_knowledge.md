# 自动驾驶感知系统：综合概述

## 1. 感知简介
感知是自动驾驶汽车（AV）的“眼睛”。它涉及从各种传感器收集数据并解释环境，以识别物体、道路特征和潜在危险。

### 关键传感器
*   **激光雷达 (LiDAR)**: 提供精确的3D点云。极其擅长深度估计，但缺乏颜色信息。
*   **摄像头 (Cameras)**: 捕捉丰富的纹理和颜色数据。对于交通信号灯检测、车道线识别和标志阅读至关重要。
*   **雷达 (Radar)**: 使用无线电波检测物体的速度和距离。在恶劣天气条件（雨、雾）下表现良好，这是摄像头和激光雷达可能挣扎的地方。

## 2. 传感器融合策略 (Sensor Fusion)
必须结合不同的传感器数据以形成连贯的世界模型。
*   **早期融合 (Early Fusion)**: 传感器的原始数据在任何处理之前进行结合。由于同步挑战，实施难度较大。
*   **晚期融合 (Late Fusion)**: 每个传感器处理独立运行（例如，摄像头检测到一辆车，雷达检测到一辆车），然后合并高级对象。实施较容易，但可能会丢失微妙的相关性。
*   **深度融合 (Deep Fusion)**: 处理不同模态的神经网络的特征图在中间层进行拼接。

## 3. 物体检测与跟踪
*   **3D 边界框估计**: 像 PointPillars 或 VoxelNet 这样的算法利用点云来估计物体的长度、宽度、高度和方向。
*   **跟踪 (MOT)**: 多目标跟踪（Multi-Object Tracking）关联跨时间帧的检测结果以估计速度和轨迹。卡尔曼滤波（Kalman Filters）常用于此。

## 4. 语义分割
将场景划分为属于特定类别（道路、人行道、建筑物、行人）的像素或点。
*   **BevFormer**: 一种流行的架构，将透视图图像转换为鸟瞰图（BEV）表示，以便于规划。

## 5. 感知中的挑战
*   **遮挡 (Occlusion)**: 物体被其他物体阻挡。
*   **恶劣天气**: 大雨、大雪或刺眼的阳光。
*   **长尾事件 (Long-tail Events)**: 罕见的场景，如穿着恐龙服装的人或运载着天空反射图像的卡车。
